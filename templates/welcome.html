{% extends "base.html" %}

{% block title %}Welcome to Sugar-AI{% endblock %}

{% block css %}
<link rel="stylesheet" href="{{ url_for('static', path='css/welcome.css') }}">
{% endblock %}

{% block header %}
<header>
  <div class="container header-container">
    <div class="logo">
      <h1>Sugar-AI</h1>
      <p>An AI-powered coding assistant for the Sugar Learning Platform</p>
    </div>
    <div class="nav-buttons">
      <a href="/oauth-login" class="nav-btn">Sign in with OAuth</a>
      <a href="/admin-login" class="nav-btn">API Key Login</a>
      <a href="/request-key" class="nav-btn primary">Request API Key</a>
    </div>
  </div>
</header>


<nav class="page-nav">
  <div class="container">
    <ul>
      <li><a href="#overview">Overview</a></li>
      <li><a href="#use-cases">Use Cases</a></li>
      <li><a href="#dashboard">Dashboard</a></li>
      <li><a href="#api">API Usage</a></li>
      <li><a href="#docs">API Documentation</a></li>
    </ul>
  </div>
</nav>
{% endblock %}

{% block content %}
<div class="container">
  <section id="overview" class="hero">
    <h2>Welcome to Sugar-AI</h2>
    <p>
      Sugar-AI is a specialized coding assistant designed to help children
      learn programming with the Sugar Learning Platform. It uses advanced
      AI to provide child-friendly explanations and code examples.
    </p>
    <div class="hero-buttons">
      <a href="/request-key" class="btn btn-accent">Get Started</a>
      <a href="https://github.com/sugarlabs/sugar-ai" class="btn">View on GitHub</a>
    </div>
  </section>

  <h2 id="use-cases" class="section-title">How Sugar-AI Can Help You</h2>

  <div class="card-grid">
    <div class="card">
      <div class="card-content">
        <h3>For Students & Teachers</h3>
        <p>
          Sugar-AI helps students and teachers learn coding with Sugar Labs
          tools:
        </p>
        <ul>
          <li>Ask questions about Pygame, GTK+3, and Sugar Toolkit</li>
          <li>Get explanations in child-friendly language</li>
          <li>Learn programming concepts step by step</li>
          <li>Receive examples tailored to Sugar activities</li>
          <li>Get kid-friendly debugging suggestions for your python programs</li>
          <li>Utilize the chat completion functionality to generate conversational model responses</li>
        </ul>
      </div>
      <div class="card-footer">
        <a href="/request-key" class="btn">Request API Key</a>
      </div>
    </div>

    <div class="card">
      <div class="card-content">
        <h3>For Developers</h3>
        <p>
          Integrate Sugar-AI with your applications using our simple API:
        </p>
        <ul>
          <li>RESTful API endpoints for easy integration</li>
          <li>Secure authentication with API keys</li>
          <li>RAG (Retrieval-Augmented Generation) for accurate answers</li>
          <li>Documented endpoints for developers</li>
        </ul>
      </div>
      <div class="card-footer">
        <a href="https://github.com/sugarlabs/sugar-ai" class="btn">View on GitHub</a>
      </div>
    </div>

    <div class="card">
      <div class="card-content">
        <h3>For Administrators</h3>
        <p>Manage Sugar-AI and monitor usage through the admin panel:</p>
        <ul>
          <li>Approve or deny API key requests</li>
          <li>Monitor system quotas</li>
          <li>Manage user permissions</li>
          <li>Control access to advanced features</li>
        </ul>
      </div>
      <div class="card-footer">
        <a href="/admin-login" class="btn btn-accent">Admin Login</a>
      </div>
    </div>
  </div>

  <h2 id="dashboard" class="section-title">Your Sugar-AI Dashboard</h2>

  <div class="card">
    <h3>Dashboard Overview</h3>
    <p>
      The Sugar-AI Dashboard is your personal control center, accessible
      after signing in with OAuth or an API key. Here's what you can do:
    </p>

    <div class="feature-grid" style="margin-top: 30px">
      <div class="feature">
        <h3>Interactive Chat</h3>
        <p>
          Ask questions directly to the AI and receive instant responses
          about Sugar development
        </p>
      </div>
      <div class="feature">
        <h3>RAG Toggle</h3>
        <p>
          Switch between knowledge-enhanced responses and direct language
          model responses
        </p>
      </div>
      <div class="feature">
        <h3>Usage Metrics</h3>
        <p>Track your API usage, remaining quota.</p>
      </div>
    </div>

    <h3 style="margin-top: 40px">Dashboard Benefits</h3>
    <ul style="margin-top: 20px">
      <li>
        <strong>No Coding Required:</strong> Interact with Sugar-AI without
        writing any code
      </li>
      <li>
        <strong>Instant Feedback:</strong> Get immediate answers to your
        programming questions
      </li>
      <li>
        <strong>Educational Focus:</strong> Explanations geared toward
        learning, not just solutions
      </li>
      <li>
        <strong>Accessible Anywhere:</strong> Use from any device with a web
        browser
      </li>
      <li>
        <strong>Admin Features:</strong> Administrators can access
        additional management tools
      </li>
    </ul>

    <div style="text-align: center; margin-top: 30px">
      <a href="/oauth-login" class="btn">Access Dashboard</a>
    </div>
  </div>

  <h2 id="api" class="section-title">API Usage</h2>

  <div class="card">
    <h3>Using the Sugar-AI API</h3>
    <p>
      Integrate Sugar-AI's capabilities into your own applications with our
      straightforward API:
    </p>

    <div class="code-example">
      <h4>Python Example</h4>
      <pre><code>import requests

# Make a request to the Sugar-AI API
api_key = "YOUR_API_KEY"
url = "https://sugar-ai.sugarlabs.org/ask"
params = {"question": "How do I create a Pygame window?"}
headers = {"X-API-Key": api_key}

response = requests.post(url, params=params, headers=headers)
result = response.json()

print(result["answer"])
</code></pre>
    </div>

    <h4 style="margin-top: 30px">API Endpoints Overview</h4>
    
    <table style="width: 100%; border-collapse: collapse; margin: 20px 0; background: white; border-radius: 8px; overflow: hidden; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
      <thead>
        <tr style="background: var(--primary-color); color: white;">
          <th style="padding: 12px; text-align: left; border-bottom: 1px solid #ddd;">Endpoint</th>
          <th style="padding: 12px; text-align: left; border-bottom: 1px solid #ddd;">Purpose</th>
          <th style="padding: 12px; text-align: left; border-bottom: 1px solid #ddd;">Input Format</th>
          <th style="padding: 12px; text-align: left; border-bottom: 1px solid #ddd;">Key Features</th>
        </tr>
      </thead>
      <tbody>
        <tr style="border-bottom: 1px solid #eee;">
          <td style="padding: 12px; font-weight: bold; color: var(--primary-color);">/ask</td>
          <td style="padding: 12px;">RAG-enabled answers</td>
          <td style="padding: 12px;">Query parameter</td>
          <td style="padding: 12px;">
            • Retrieval-Augmented Generation<br>
            • Sugar/Pygame/GTK documentation<br>
            • Child-friendly responses
          </td>
        </tr>
        <tr style="border-bottom: 1px solid #eee;">
          <td style="padding: 12px; font-weight: bold; color: var(--primary-color);">/ask-llm</td>
          <td style="padding: 12px;">Direct LLM without RAG</td>
          <td style="padding: 12px;">Query parameter</td>
          <td style="padding: 12px;">
            • No document retrieval<br>
            • Direct model access<br>
            • Faster responses
          </td>
        </tr>
        <tr style="border-bottom: 1px solid #eee;">
          <td style="padding: 12px; font-weight: bold; color: var(--primary-color);">/ask-llm-prompted</td>
          <td style="padding: 12px;">Custom prompt with advanced controls</td>
          <td style="padding: 12px;">JSON body</td>
          <td style="padding: 12px;">
            • Custom system prompts<br>
            • Configurable generation parameters<br>
            • Maximum flexibility
          </td>
        </tr>
        <tr>
          <td style="padding: 12px; font-weight: bold; color: var(--primary-color);">/debug</td>
          <td style="padding: 12px;">Python code debugging</td>
          <td style="padding: 12px;">Query parameters</td>
          <td style="padding: 12px;">
            • Kid-friendly debugging suggestions<br>
            • Context mode for explanations<br>
            • Educational focus
          </td>
        </tr>
      </tbody>
    </table>

    <h4 style="margin-top: 30px">Quick Reference</h4>
    <ul>
      <li>
        <strong>/ask</strong> - Get answers with Retrieval-Augmented
        Generation
      </li>
      <li>
        <strong>/ask-llm</strong> - Get direct responses from the language
        model
      </li>
      <li>
        <strong>/ask-llm-prompted(Prompted Mode[default])</strong> - Custom prompts with advanced generation controls
      </li>
      <li>
        <strong>/ask-llm-prompted(Chat Mode)</strong> - Utilize the chat completion functionality to generate conversational model responses
      </li>
      <li>
        <strong>/debug</strong> - Get kid-friendly debugging suggestions for Python code
      </li>
    </ul>

    <div style="text-align: center; margin-top: 30px">
      <a href="/request-key" class="btn btn-accent">Get Your API Key</a>
    </div>
  </div>
  
  <div class="documentation-section">
    <h2 h2 id="docs" class="section-title">API Endpoints Documentation</h2>
    
    <div class="endpoint">
      <h3>Ask Question (RAG Enhanced)</h3>
      <div class="endpoint-method">POST</div>
      <div class="endpoint-url">/ask?question={your_question}</div>
      <p>Ask a coding question using Retrieval-Augmented Generation for enhanced context and precision.</p>
      
      <div class="endpoint-details">
        <h4>Headers:</h4>
        <pre>X-API-Key: your_api_key</pre>
        
        <h4>Example Request:</h4>
        <pre>curl -X POST "http://localhost:8000/ask?question=How%20do%20I%20create%20a%20Python%20class?" \
    -H "X-API-Key: your_api_key"</pre>
        
        <h4>Response Format:</h4>
        <pre>{
    "answer": "Detailed explanation about Python classes...",
    "user": "Your Username",
    "quota": {"remaining": 95, "total": 100}
  }</pre>
      </div>
    </div>
    
    <div class="endpoint">
      <h3>Debug Python Code</h3>
      <div class="endpoint-method">POST</div>
      <div class="endpoint-url">/debug?code={your_python_code}&context={true|false}</div>
      <p>Send your python code to get debugging suggestions, with context mode for kid-friendly code explanations.</p>
      
      <div class="endpoint-details">
        <h4>Headers:</h4>
        <pre>X-API-Key: your_api_key</pre>

        <h4>Params:</h4>
        <pre>code: your_python_code,
context: true | false  # turn on context mode (explains code in a kid-friendly way)</pre>

        <h4>Example Request:</h4>
        <pre>curl -X POST "http://localhost:8000/debug?code=How%20do%20I%20create%20a%20Python%20class&context=False?" \
    -H "X-API-Key: your_api_key"</pre>
        
        <h4>Response Format:</h4>
        <pre>{
    "answer": "Debugging suggestions for your python code....",
    "user": "Your Username",
    "quota": {"remaining": 95, "total": 100}
  }</pre>
      </div>
    </div>

    <div class="endpoint">
      <h3>Chat Completions</h3>
      <div class="endpoint-method">POST</div>
      <div class="endpoint-url">ask-llm-prompted(Chat Mode)</div>
      <p>Send your chat history(along with system prompt) to get responses from the language model for conversational responses.</p>
      
      <div class="endpoint-details">
        <h4>Headers:</h4>
        <pre>Content-Type: application/json</pre>
        <pre>X-API-Key: your_api_key</pre>

        <h4>Params:</h4>
        <pre>chat: true | false (set true for chat mode)
messages:
  [
    {role: "system", content:(system_prompt)},
    {role: "user", content:(user_message)},
    {role: "assistant", content:(assistant_message)},
    {role: "user", content:(user_message)},......
  ],
max_length: maximum tokens in the output,
truncation: whether to cut off text exceeding limits,
repetition_penalty: penalizes repeated phrases,
temperature: controls randomness/creativity,
top_p: nucleus sampling for diversity (probability cutoff),
top_k: restricts word choices to the top k candidates</pre>

        <h4>Example Request:</h4>
        <pre>curl -X POST "http://localhost:8000/ask-llm-prompted" \
-H "Content-Type: application/json" \
-H "X-API-KEY: sugarai2024" \
-d '{
  "chat": true,
  "messages": [
    {"role": "system", "content": "You are a helpful AI assistant. Reply in 2-3 sentences."},
    {"role": "user", "content": "What is machine learning?"},
    {"role": "assistant", "content": "Machine learning is a subset of artificial intelligence..."},
    {"role": "user", "content": "Can you give me a simple example?"}
],
    "max_length": 512, #optional
    "truncation": false, #optional
    "repetition_penalty": 1.1, #optional
    "temperature": 0.7, #optional
    "top_p": 0.9, #optional
    "top_k": 40 #optional
}'</pre>
        
        <h4>Response Format:</h4>
        <pre>{
    "choices": [
        {
        "message": {
            "role": "assistant",
            "content": "Sure! Machine learning involves algorithms....."
        },
        "index": 0,
        "finish_reason": "stop"
        }
    ],
    "user": "Admin Key",
    "quota": {
        "remaining": 99,
        "total": 100
    },
    "generation_params": {
        "max_length": 512,
        "truncation": false,
        "repetition_penalty": 1.1,
        "temperature": 0.7,
        "top_p": 0.9,
        "top_k": 40
    }
}</pre>
      </div>
    </div>
    
    <div class="endpoint">
      <h3>Direct LLM Question</h3>
      <div class="endpoint-method">POST</div>
      <div class="endpoint-url">/ask-llm?question={your_question}</div>
      <p>Ask a question directly to the LLM without RAG enhancement.</p>
      
      <div class="endpoint-details">
        <h4>Headers:</h4>
        <pre>X-API-Key: your_api_key</pre>
        
        <h4>Example Request:</h4>
        <pre>curl -X POST "http://localhost:8000/ask-llm?question=What%20is%20the%20difference%20between%20lists%20and%20tuples?" \
    -H "X-API-Key: your_api_key"</pre>
      </div>
    </div>
    
    <div class="endpoint">
      <h3>Custom Prompt with Advanced Controls</h3>
      <div class="endpoint-method">POST</div>
      <div class="endpoint-url">/ask-llm-prompted</div>
      <p>A powerful endpoint that allows custom system prompts and configurable generation parameters for maximum flexibility.</p>
      
      <div class="endpoint-details">
        <h4>Headers:</h4>
        <pre>X-API-Key: your_api_key
Content-Type: application/json</pre>
        
        <h4>Features:</h4>
        <ul>
          <li>Custom system prompts for specific use cases</li>
          <li>Configurable generation parameters</li>
          <li>Direct LLM access without RAG</li>
          <li>Suitable for specialized activities and applications</li>
        </ul>
        
        <h4>Basic Usage:</h4>
        <pre>curl -X POST "http://localhost:8000/ask-llm-prompted" \
  -H "X-API-Key: your_api_key" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "How do I create a Pygame window?",
    "custom_prompt": "You are a Python expert. Provide detailed code examples with explanations."
  }'</pre>
        
        <h4>Advanced Usage with Generation Parameters:</h4>
        <pre>curl -X POST "http://localhost:8000/ask-llm-prompted" \
  -H "X-API-Key: your_api_key" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Write a function to calculate fibonacci numbers",
    "custom_prompt": "You are a coding tutor. Explain step-by-step with comments.",
    "max_length": 1024,
    "truncation": true,
    "repetition_penalty": 1.1,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50
  }'</pre>
        
        <h4>Request Parameters:</h4>
        <ul>
          <li><strong>question</strong> (required): The question or task to process</li>
          <li><strong>custom_prompt</strong> (required): Your custom system prompt</li>
          <li><strong>max_length</strong> (optional, default: 1024): Maximum length of generated response</li>
          <li><strong>truncation</strong> (optional, default: true): Whether to truncate long inputs</li>
          <li><strong>repetition_penalty</strong> (optional, default: 1.1): Controls repetition (1.0 = no penalty, >1.0 = less repetition)</li>
          <li><strong>temperature</strong> (optional, default: 0.7): Controls randomness (0.0 = deterministic, 1.0 = very random)</li>
          <li><strong>top_p</strong> (optional, default: 0.9): Nucleus sampling (0.1 = focused, 0.9 = diverse)</li>
          <li><strong>top_k</strong> (optional, default: 50): Limits vocabulary to K most likely words</li>
        </ul>
        
        <h4>Response Format:</h4>
        <pre>{
  "answer": "Here's how to create a Pygame window:...",
  "user": "Your Username",
  "quota": {"remaining": 95, "total": 100},
  "generation_params": {
    "max_length": 1024,
    "truncation": true,
    "repetition_penalty": 1.1,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50
  }
}</pre>

        <h4>Generation Parameter Guidelines:</h4>
        <ul>
          <li><strong>For Code:</strong> temperature: 0.2-0.4, top_p: 0.8, repetition_penalty: 1.1</li>
          <li><strong>For Creative Content:</strong> temperature: 0.7-0.9, top_p: 0.9, repetition_penalty: 1.2</li>
          <li><strong>For Factual Answers:</strong> temperature: 0.3-0.5, top_p: 0.7, repetition_penalty: 1.0</li>
        </ul>
        
        <h4>Use Cases:</h4>
        <p>Different activities can use different system prompts and generation parameters to achieve a model that is personalized to specific activity needs. Some example are: </p>
        <ul>
          <li>Speak-AI activity can use this endpoint with custom prompts for different personas in the chatbot</li>
          <li>Pippy Activity can use this endpoint with custom prompts to make a code-debugger</li>
        </ul>
      </div>
    </div>
    
   
    
    <div class="endpoint admin-only">
      <h3>Change Model (Admin Only)</h3>
      <div class="endpoint-method">POST</div>
      <div class="endpoint-url">/change-model?model={model_name}&api_key={admin_key}&password={admin_password}</div>
      <p>Change the LLM model being used for responses. Requires admin API key and password.</p>
      
      <div class="endpoint-details">
        <h4>Example Request:</h4>
        <pre>curl -X POST "http://localhost:8000/change-model?model=Qwen/Qwen2-1.5B-Instruct&api_key=admin_key&password=admin_password"</pre>
        
       
        </ul>
      </div>
    </div>
  </div>
</div>
{% endblock %}

{% block js %}
<script src="{{ url_for('static', path='js/welcome.js') }}"></script>
{% endblock %}
